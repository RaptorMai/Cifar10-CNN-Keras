{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for Image Classification\n",
    "\n",
    "The code below assumes Python 3.6 with Tensorflow installed.  \n",
    "\n",
    "You may need to additionally install numpy, scipy, matplotlib, scikit-learn, seaborn, opencv-python, and pillow if you don't already have these installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Download the Cifar-10 data <a>https://www.cs.toronto.edu/~kriz/cifar.html</a> and update PATH in cell [2].\n",
    "\n",
    "2. This is a very basic model for explaining the pipeline of CNN  \n",
    "3. Improved version is in another Notebook in the same repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Cifar-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#import cPickle\n",
    "import _pickle as cPickle\n",
    "import pandas as pd \n",
    "from numpy import argmax\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow.python.keras\n",
    "from tensorflow.python.keras.models import Sequential \n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from tensorflow.python.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"cifar/cifar-10-batches-py/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar(object):\n",
    "    def __init__(self, input_path, dropout_index):\n",
    "        self.input_path = input_path\n",
    "        self.dropout_index = dropout_index\n",
    "        self._get_data()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = cPickle.load(fo, encoding='latin1')\n",
    "        return dict\n",
    "    \n",
    "    @staticmethod\n",
    "    def _getfiles(path):\n",
    "        files = []\n",
    "        for file in os.listdir(path):\n",
    "            if \"data_batch\" in file:\n",
    "                files.append(file)\n",
    "        return files\n",
    " \n",
    "    def _get_data(self):\n",
    "\n",
    "        cifar_9_data = []\n",
    "        cifar_9_labels = []\n",
    "        cifar_1_data = []\n",
    "        cifar_1_labels = []\n",
    "        \n",
    "        files = self._getfiles(self.input_path)\n",
    "\n",
    "        for batch_file in files:\n",
    "            batch = self._unpickle('{0}/{1}'.format(PATH, batch_file))\n",
    "            labels = np.array(batch['labels'])\n",
    "            keep_indexs = np.zeros(len(labels), dtype=bool)\n",
    "            keep_indexs[labels!=self.dropout_index] = True\n",
    "            cifar_9_data.append(batch['data'][keep_indexs])\n",
    "            cifar_9_labels.append(labels[keep_indexs])\n",
    "            drop_indexs = np.invert(keep_indexs)\n",
    "            cifar_1_data.append(batch['data'][drop_indexs])\n",
    "            cifar_1_labels.append(labels[drop_indexs])\n",
    "\n",
    "        cifar_9_data = np.transpose(np.concatenate(cifar_9_data).reshape(-1,3,32,32), (0, 2, 3, 1))\n",
    "        cifar_9_labels = np.concatenate(cifar_9_labels)\n",
    "        cifar_1_data = np.transpose(np.concatenate(cifar_1_data).reshape(-1,3,32,32), (0, 2, 3, 1))\n",
    "        cifar_1_labels = np.concatenate(cifar_1_labels)\n",
    "        \n",
    "        self.data = cifar_9_data.astype('float32')/255\n",
    "        self.labels = tensorflow.keras.utils.to_categorical(cifar_9_labels, 10)\n",
    "        \n",
    "        self.trans_data = cifar_1_data.astype('float32')/255\n",
    "        self.trans_labels = tensorflow.keras.utils.to_categorical(cifar_1_labels, 10)\n",
    "        \n",
    "    def next_data_batch(self, num):\n",
    "        idx = np.arange(0, len(self.labels))\n",
    "        np.random.shuffle(idx)\n",
    "        idx = idx[:num]\n",
    "        \n",
    "        return self.data[idx], self.labels[idx]\n",
    "        \n",
    "    def next_trans_data_batch(self, num):\n",
    "        idx = np.arange(0, len(self.trans_labels))\n",
    "        np.random.shuffle(idx)\n",
    "        idx = idx[:num]\n",
    "        batch = self.data[idx]\n",
    "        \n",
    "        return self.trans_data[idx], self.trans_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar = Cifar(PATH, 9)\n",
    "data,labels = cifar.next_data_batch(6)\n",
    "plt.figure(figsize=(18, 10))\n",
    "reference = data\n",
    "for i in range(reference.shape[0]):\n",
    "    plt.subplot(int(reference.shape[0]/6)+1, 6, i+1)\n",
    "    plt.imshow(reference[i])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Keras deep net model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 2 # 50 is required for your final submission, but you can decrease for quick testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=cifar.data.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = tensorflow.keras.optimizers.RMSprop(lr=0.001)\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(cifar.data[:20000], cifar.labels[:20000],\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(cifar.data[20001:30000], cifar.labels[20001:30000]),\n",
    "                    epochs=epochs,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show train and test performance vs. epochs of gradient descent training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show confusion matrix of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Names(not gaven as metadata)\n",
    "Label_names = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(cifar.data[30000:]), axis=1)   \n",
    "y_label = np.argmax(cifar.labels[30000:],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, \n",
    "                           figsize = (10,7), fontsize=14):\n",
    "\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Cifar-9 Confusion Matrix\n",
    "print_confusion_matrix(confusion_matrix(y_label, y_pred), \n",
    "                       Label_names[:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show predicted and actual labels for random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_examples(image, label, predict, Label_names, sample_size=5):\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    reference = image[:sample_size]\n",
    "    for i in range(reference.shape[0]):\n",
    "        plt.subplot(int(reference.shape[0]/sample_size)+1, \n",
    "                    sample_size, i+1)\n",
    "        plt.imshow(reference[i])\n",
    "        plt.xlabel('label:{0}\\n pred:{1}'.format(Label_names[label[i]],\n",
    "                                                 Label_names[pred[i]]), \n",
    "                   fontsize=13)\n",
    "    plt.show()\n",
    "image,label = cifar.next_data_batch(5)\n",
    "label = np.argmax(label, axis=1)\n",
    "pred = np.argmax(model.predict(image), axis=1)\n",
    "random_examples(image, label, pred, Label_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
